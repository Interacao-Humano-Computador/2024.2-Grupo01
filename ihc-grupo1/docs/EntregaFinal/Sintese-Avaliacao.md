## Avaliação dos protótipos

### Introdução

Este documento apresenta uma síntese das avaliações dos protótipos realizadas no projeto. A síntese combina dados sobre os entrevistadores, número de participantes e membros do grupo que participaram de cada avaliação.

Foram realizadas avaliações de diferentes tipos de protótipos e modelos conceituais ao longo do projeto, conforme apresentado na Tabela 1.

## Metodologias de Entrevista e Teste de Usabilidade

De acordo com Barbosa e Silva (2021), as entrevistas e os testes de usabilidade são métodos importantes na avaliação de Interação Humano-Computador (IHC).

<details >

<summary>Entrevistas</summary>

As entrevistas são um método de investigação que permite coletar informações detalhadas sobre as experiências, opiniões e preferências dos usuários. Barbosa e Silva destacam os seguintes pontos sobre entrevistas:

- **Tipos de entrevistas**: Podem ser estruturadas, semiestruturadas ou não estruturadas.
- **Preparação**: É crucial elaborar um roteiro com os tópicos a serem abordados.
- **Condução**: O entrevistador deve criar um ambiente confortável e evitar influenciar as respostas.
- **Registro**: As entrevistas devem ser gravadas (com permissão) ou anotadas detalhadamente.
- **Análise**: Os dados coletados devem ser organizados e analisados para identificar padrões e insights relevantes.

</details>

<details>
<summary>Testes de Usabilidade</summary>

Os testes de usabilidade são um método de observação que avalia a interação do usuário com o sistema. Barbosa e Silva apresentam as seguintes etapas e considerações:

1. **Preparação**:
   - Definir os objetivos do teste
   - Selecionar os participantes
   - Preparar as tarefas e os materiais

2. **Execução**:
   - Orientar os participantes sobre o processo
   - Observar e registrar as interações
   - Coletar dados quantitativos e qualitativos

3. **Análise e Relatório**:
   - Organizar e analisar os dados coletados
   - Identificar problemas de usabilidade
   - Elaborar um relatório com os resultados e recomendações

4. **Métricas comuns**:
   - Tempo de conclusão da tarefa
   - Taxa de sucesso
   - Número de erros
   - Satisfação do usuário

</details>

<center>

**Tabela 1** - Síntese das avaliações dos protótipos

| Protótipo Avaliado | Método | Entrevistadores | Nº de Participantes | Membros do Grupo Participantes | Resultados |
|--------------------|--------|-----------------|---------------------|--------------------------------|------------|
| Storyboard | Entrevista | Davi, João Ribeiro | 2 | Davi, João Ribeiro | [Resultado Storyboard](../DesignAvaliacaoDesenvolvimento/Nivel2/relatoStory.md) |
| Análise de Tarefas | Entrevista | Carla, João Ribeiro | 2 | Carla, João Ribeiro | [Resultado Análise de Tarefas](../DesignAvaliacaoDesenvolvimento/Nivel2/avaliacao_hta.md) |
| Protótipo de Papel | Entrevista | Davi | 1 | Davi | [Resultado Protótipo de papel](../DesignAvaliacaoDesenvolvimento/Nivel3/Relatopapel.md) |
| Protótipo de Alta Fidelidade | Teste de usabilidade | Carla, Gabriel | 2 | Carla, Gabriel | [Resultado Protótipo Alta Fidelidade](../DesignAvaliacaoDesenvolvimento/Nivel4/relatoAF.md) |

<p align="center"><b>Autor:</b> <a href="https://github.com/GabrielSMonteiro">Gabriel Monteiro</a></p>

</center>

Através dessas avaliações, foi possível obter insights valiosos sobre o desempenho e a usabilidade dos protótipos desenvolvidos. As avaliações desempenharam um papel crucial na identificação de pontos fortes e áreas que necessitavam de aprimoramento.

Os resultados das avaliações serviram como base para ajustes e melhorias nos protótipos, contribuindo significativamente para a evolução do projeto. Além disso, as avaliações proporcionaram à equipe uma oportunidade valiosa de interagir diretamente com os usuários e aplicar na prática os métodos de entrevista e teste de usabilidade propostos na disciplina.

Em suma, as avaliações realizadas nos protótipos forneceram informações cruciais que guiaram o desenvolvimento do projeto, permitindo uma melhor compreensão das necessidades e expectativas dos usuários.

# Bibliografia

> 1. Lichess. Análise Hierárquica de Tarefas. Repositório do Grupo Lichess da disciplina de Interação Humano Computador da Universidade de Brasília, 2022.2. Disponível em: <https://interacao-humano-computador.github.io/2022.2-Lichess/design_avaliacao_desenvolvimento/nivel_1/storyboard/planejamento_avaliacao/> Acesso em 08/02/2025 ás 21:00

> 2. BARBOSA, S. D. J.; SILVA, B. S. Interação Humano-Computador. Elsevier, 2011.

> 3. Bilheteria Digital. Análise Hierárquica de Tarefas. Repositório do Grupo Bilheteria Digital da disciplina de Interação Humano Computador da Universidade de Brasília, 2023.1. Disponível em: <https://interacao-humano-computador.github.io/2023.1-BilheteriaDigital/analise-de-requisitos/analise-de-tarefas/hta/.> Acesso em 08/02/2025 ás 21:01


## :round_pushpin: Histórico de Versão 

<div align="center">
    <table>
        <tr>
            <th>Data</th>
            <th>Versão</th>
            <th>Descrição</th>
            <th>Autor</th>
            <th>Data da Revisão</th>
            <th>Revisor</th>
        </tr>
        <tr>
            <td>09/02</td>
            <td>1.0</td>
            <td>Criação do documento</td>
            <td><a href="https://github.com/GabrielSMonteiro">Gabriel Monteiro</a></td>
            <td>09/02</td>
            <td><a href="https://github.com/Joa0V">João Ribeiro</a></td>
        </tr>
    </table>
</div>
